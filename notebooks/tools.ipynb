{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a552cab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shivamkaushik/Code/ik-agent\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c4f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3173719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>ik_key</th>\n",
       "      <th>value_type</th>\n",
       "      <th>allowed_values</th>\n",
       "      <th>constraints</th>\n",
       "      <th>tags</th>\n",
       "      <th>used_in</th>\n",
       "      <th>description</th>\n",
       "      <th>example_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>width</td>\n",
       "      <td>width</td>\n",
       "      <td>number, arithmetic_expression, \"\"\"auto\"\"\"</td>\n",
       "      <td>integer &gt; 1 (px) OR 0 &lt; w &lt; 1 (percentage) OR ...</td>\n",
       "      <td>Auto width from Client Hint Sec-CH-Width.</td>\n",
       "      <td>[resize, crop]</td>\n",
       "      <td>image</td>\n",
       "      <td>Output width. If only w is provided, height au...</td>\n",
       "      <td>### Example 1\\n\\n**Integer value**\\n\\n```pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>height</td>\n",
       "      <td>height</td>\n",
       "      <td>number, arithmetic_expression, \"\"\"auto\"\"\"</td>\n",
       "      <td>integer &gt; 1 (px) OR 0 &lt; w &lt; 1 (percentage) OR ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[resize]</td>\n",
       "      <td>image</td>\n",
       "      <td>Output height. If only h is provided, width au...</td>\n",
       "      <td>### Example 1\\n\\n**Integer value**\\n\\n```pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aspect Ratio</td>\n",
       "      <td>aspect_ratio</td>\n",
       "      <td>&lt;w&gt;-&lt;h&gt;, arithmetic_expression</td>\n",
       "      <td>width-height, arithmetic expression</td>\n",
       "      <td>Must be used with either w or h. Ignored if bo...</td>\n",
       "      <td>[resize]</td>\n",
       "      <td>image</td>\n",
       "      <td>Aspect ratio (width:height).</td>\n",
       "      <td>### Example 1\\n\\n**width = 400, height = 300, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crop Mode</td>\n",
       "      <td>crop_mode</td>\n",
       "      <td>enum</td>\n",
       "      <td>pad_resize | pad_extract | extract</td>\n",
       "      <td>pad_resize\\n\\n* Requires **both `w` and `h`** ...</td>\n",
       "      <td>[resize, crop]</td>\n",
       "      <td>image</td>\n",
       "      <td>`cm-pad_resize` resizes the image to fit withi...</td>\n",
       "      <td>## pad_resize\\n\\n### Example: Equal padding on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crop</td>\n",
       "      <td>crop</td>\n",
       "      <td>enum</td>\n",
       "      <td>force | at_max_enlarge | at_least | maintain_r...</td>\n",
       "      <td>## force (`force`)\\n\\n* Requires **both `w` an...</td>\n",
       "      <td>[crop]</td>\n",
       "      <td>image</td>\n",
       "      <td>**force (`force`)**\\nResizes the image to the ...</td>\n",
       "      <td>---\\n\\n## force (`force`)\\n\\n### This example ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parameter_name        ik_key                                 value_type  \\\n",
       "0          width         width  number, arithmetic_expression, \"\"\"auto\"\"\"   \n",
       "1         height        height  number, arithmetic_expression, \"\"\"auto\"\"\"   \n",
       "2   Aspect Ratio  aspect_ratio             <w>-<h>, arithmetic_expression   \n",
       "3      Crop Mode     crop_mode                                       enum   \n",
       "4           Crop          crop                                       enum   \n",
       "\n",
       "                                      allowed_values  \\\n",
       "0  integer > 1 (px) OR 0 < w < 1 (percentage) OR ...   \n",
       "1  integer > 1 (px) OR 0 < w < 1 (percentage) OR ...   \n",
       "2                width-height, arithmetic expression   \n",
       "3                 pad_resize | pad_extract | extract   \n",
       "4  force | at_max_enlarge | at_least | maintain_r...   \n",
       "\n",
       "                                         constraints            tags used_in  \\\n",
       "0          Auto width from Client Hint Sec-CH-Width.  [resize, crop]   image   \n",
       "1                                                NaN        [resize]   image   \n",
       "2  Must be used with either w or h. Ignored if bo...        [resize]   image   \n",
       "3  pad_resize\\n\\n* Requires **both `w` and `h`** ...  [resize, crop]   image   \n",
       "4  ## force (`force`)\\n\\n* Requires **both `w` an...          [crop]   image   \n",
       "\n",
       "                                         description  \\\n",
       "0  Output width. If only w is provided, height au...   \n",
       "1  Output height. If only h is provided, width au...   \n",
       "2                       Aspect ratio (width:height).   \n",
       "3  `cm-pad_resize` resizes the image to fit withi...   \n",
       "4  **force (`force`)**\\nResizes the image to the ...   \n",
       "\n",
       "                                       example_usage  \n",
       "0  ### Example 1\\n\\n**Integer value**\\n\\n```pytho...  \n",
       "1  ### Example 1\\n\\n**Integer value**\\n\\n```pytho...  \n",
       "2  ### Example 1\\n\\n**width = 400, height = 300, ...  \n",
       "3  ## pad_resize\\n\\n### Example: Equal padding on...  \n",
       "4  ---\\n\\n## force (`force`)\\n\\n### This example ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"static/ik_transforms.csv\")\n",
    "df.tags = df.tags.apply(lambda x: [xx.strip() for xx in x.split(\",\")])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a28f095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crop', 'resize', 'smart_crop'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags = set()\n",
    "for t in df.tags.values:\n",
    "    unique_tags.update(t)\n",
    "\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AsyncOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SMALL_LLM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a strict classifier.\n",
    "\n",
    "Your task:\n",
    "Given a user query, identify:\n",
    "1. Which ImageKit transformation METHODS are required\n",
    "2. Which semantic TAGS are relevant\n",
    "\n",
    "Rules:\n",
    "- You MUST choose tags ONLY from the provided list\n",
    "- You MUST choose methods ONLY from the provided list\n",
    "- Do NOT invent new tags or methods\n",
    "- Do NOT generate parameter values\n",
    "- Do NOT generate ImageKit keys\n",
    "\n",
    "Valid methods:\n",
    "{methods_json}\n",
    "\n",
    "Valid tags:\n",
    "{tags_json}\n",
    "\n",
    "Output STRICT JSON only.\n",
    "\n",
    "Format:\n",
    "{{\n",
    "  \"methods\": [\"method_name\"],\n",
    "  \"tags\": [\"tag1\", \"tag2\"]\n",
    "}}\n",
    "\n",
    "User query:\n",
    "{user_query}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def build_tag_block(tags: set[str]) -> str:\n",
    "    \"\"\"\n",
    "    Render tags in a strict, LLM-friendly format.\n",
    "    \"\"\"\n",
    "    return json.dumps(sorted(tags), indent=2)\n",
    "\n",
    "\n",
    "def build_small_llm_prompt(\n",
    "    user_query: str,\n",
    "    valid_methods: list[str],\n",
    "    valid_tags: set[str],\n",
    ") -> str:\n",
    "    return SMALL_LLM_PROMPT_TEMPLATE.format(\n",
    "        user_query=user_query,\n",
    "        methods_json=json.dumps(valid_methods, indent=2),\n",
    "        tags_json=json.dumps(sorted(valid_tags), indent=2),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53367097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a strict classifier.\n",
      "\n",
      "Your task:\n",
      "Given a user query, identify:\n",
      "1. Which ImageKit transformation METHODS are required\n",
      "2. Which semantic TAGS are relevant\n",
      "\n",
      "Rules:\n",
      "- You MUST choose tags ONLY from the provided list\n",
      "- You MUST choose methods ONLY from the provided list\n",
      "- Do NOT invent new tags or methods\n",
      "- Do NOT generate parameter values\n",
      "- Do NOT generate ImageKit keys\n",
      "\n",
      "Valid methods:\n",
      "[\n",
      "  \"resize_and_crop\",\n",
      "  \"image_overlay\",\n",
      "  \"text_overlay\"\n",
      "]\n",
      "\n",
      "Valid tags:\n",
      "[\n",
      "  \"crop\",\n",
      "  \"resize\",\n",
      "  \"smart_crop\"\n",
      "]\n",
      "\n",
      "Output STRICT JSON only.\n",
      "\n",
      "Format:\n",
      "{\n",
      "  \"methods\": [\"method_name\"],\n",
      "  \"tags\": [\"tag1\", \"tag2\"]\n",
      "}\n",
      "\n",
      "User query:\n",
      "user_query\n"
     ]
    }
   ],
   "source": [
    "user_query = \"user_query\"\n",
    "\n",
    "prompt = build_small_llm_prompt(\n",
    "    user_query=user_query,\n",
    "    valid_methods=[\n",
    "        \"resize_and_crop\",\n",
    "        \"image_overlay\",\n",
    "        \"text_overlay\",\n",
    "    ],\n",
    "    valid_tags=unique_tags,\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e41deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "async def small_llm_filter(user_query: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Uses a small, cheap model for intent classification.\n",
    "    Returns:\n",
    "      {\n",
    "        \"methods\": [...],\n",
    "        \"tags\": [...]\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = build_small_llm_prompt(\n",
    "        user_query=user_query,\n",
    "        valid_methods=[\n",
    "            \"resize_and_crop\",\n",
    "            \"image_overlay\",\n",
    "            \"text_overlay\",\n",
    "        ],\n",
    "        valid_tags=unique_tags,\n",
    "    )\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # cheap + fast\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a strict JSON-only classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8eb99862",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"resize image to 300x300 and add padding of 50 pixels\"\n",
    "\n",
    "output = await small_llm_filter(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77945c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_csv_rows(\n",
    "#     df,\n",
    "#     methods: List[str],\n",
    "#     tags: List[str],\n",
    "# ) -> Dict[str, List[dict]]:\n",
    "#     \"\"\"\n",
    "#     Filters CSV rows based on used_in and tags.\n",
    "#     Groups results by method.\n",
    "#     \"\"\"\n",
    "\n",
    "#     result: Dict[str, List[dict]] = {}\n",
    "\n",
    "#     for row in rows:\n",
    "#         if row[\"used_in\"] not in methods:\n",
    "#             continue\n",
    "\n",
    "#         row_tags = [t.strip() for t in row[\"tags\"].split(\",\")]\n",
    "#         if not any(tag in row_tags for tag in tags):\n",
    "#             continue\n",
    "\n",
    "#         result.setdefault(row[\"used_in\"], []).append(row)\n",
    "\n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = df.tags.apply(lambda x: len(set(output[\"tags\"]).intersection(set(x))) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481611a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_metadata = df[cond].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b25fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_LLM_PROMPT = \"\"\"\n",
    "You are an ImageKit transformation generator.\n",
    "\n",
    "You are given:\n",
    "1. A user query\n",
    "2. A list of VALID parameters for a specific method\n",
    "   (including constraints, allowed values, and examples)\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the provided parameters\n",
    "- Use parameter_name (NOT ImageKit short keys)\n",
    "- Do NOT invent parameters\n",
    "- Do NOT invent methods\n",
    "- Do NOT include null or unused parameters\n",
    "- Output MUST be valid JSON\n",
    "- Output MUST match the schema exactly\n",
    "\n",
    "Schema:\n",
    "[\n",
    "  {\n",
    "    \"method\": \"<method_name>\",\n",
    "    \"params\": { \"<parameter_name>\": <value> }\n",
    "  }\n",
    "]\n",
    "\n",
    "If the query cannot be satisfied using the provided parameters,\n",
    "return an empty array [].\n",
    "\n",
    "User query:\n",
    "{{USER_QUERY}}\n",
    "\n",
    "Allowed parameters metadata:\n",
    "{{FILTERED_PARAMETER_METADATA}}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "async def big_llm_generate(\n",
    "    user_query: str,\n",
    "    filtered_metadata: Dict[str, List[dict]],\n",
    ") -> List[dict]:\n",
    "    \"\"\"\n",
    "    Generates [{method, params}] using filtered metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = BIG_LLM_PROMPT.replace(\"{{USER_QUERY}}\", user_query).replace(\n",
    "        \"{{FILTERED_PARAMETER_METADATA}}\", json.dumps(filtered_metadata, indent=2)\n",
    "    )\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",  # stronger reasoning\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You output valid JSON only.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6928d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await big_llm_generate(\n",
    "    user_query=user_query,\n",
    "    filtered_metadata=filtered_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50c3fec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'method': 'resize_and_crop',\n",
       "  'params': {'width': 300, 'height': 300, 'crop_mode': 'pad_resize'}}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f06ee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "from strands import tool\n",
    "from src.utils.utils import (\n",
    "    embed_query,\n",
    "    detect_sources,\n",
    "    get_query_keywords_using_model,\n",
    "    maybe_filter,\n",
    ")\n",
    "\n",
    "from src.utils.utils import ImagekitInformationSource\n",
    "from src.config import TYPESENSE_CLIENT, TYPESENSE_MODEL_PAYLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad7f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('imagekit_guides', 'imagekit_community')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36a4c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_docs(\n",
    "    *,\n",
    "    query: str,\n",
    "    sources: Optional[List[str]] = None,\n",
    "    conversation_id: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run a Typesense semantic chat query grounded in ImageKit docs.\n",
    "    \"\"\"\n",
    "    sources = [\n",
    "        ImagekitInformationSource.ImagekitGuides.value,\n",
    "        ImagekitInformationSource.ImagekitCommunity.value,\n",
    "    ]\n",
    "    keywords = await get_query_keywords_using_model(query)\n",
    "    enriched_query = f\"{query}, Keywords: {', '.join(keywords)}\" if keywords else query\n",
    "\n",
    "    vector = await embed_query(enriched_query)\n",
    "    embed_str = json.dumps(vector, separators=(\",\", \":\"))\n",
    "\n",
    "    search_params = {\n",
    "        \"collection\": os.getenv(\"TYPESENSE_COLLECTION\", \"\"),\n",
    "        \"query_by\": (\n",
    "            \"section_content,summary,page_description,keywords,\"\n",
    "            \"lvl0,lvl1,lvl2,lvl3,lvl4,lvl5,lvl6\"\n",
    "        ),\n",
    "        \"query_by_weights\": \"3,2,2,1,1,1,1,1,1,1,1\",\n",
    "        \"vector_query\": f\"content_embedding:({embed_str},k:60)\",\n",
    "        \"limit\": 10,\n",
    "        \"rerank_hybrid_matches\": True,\n",
    "        \"exclude_fields\": \"content_embedding\",\n",
    "        \"filter_by\": f\"source:={sources}\",\n",
    "    }\n",
    "\n",
    "    common_params: Dict[str, Any] = {\n",
    "        \"q\": enriched_query,\n",
    "        \"conversation\": False,\n",
    "        \"conversation_model_id\": TYPESENSE_MODEL_PAYLOAD[\"id\"],\n",
    "    }\n",
    "    if conversation_id:\n",
    "        common_params[\"conversation_id\"] = conversation_id\n",
    "\n",
    "    payload = {\"searches\": [search_params]}\n",
    "    return TYPESENSE_CLIENT.multi_search.perform(payload, common_params=common_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa42b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await search_docs(query=\"video smart crop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def group_search_results(search_results: List[Tuple[str, float, dict]]):\n",
    "    \"\"\"\n",
    "    Organize fused search results into a dictionary grouped by source_url.\n",
    "\n",
    "    Structure:\n",
    "        {\n",
    "            source_url: {\n",
    "                \"page_title\": str,\n",
    "                \"page_description\": str,\n",
    "                \"content\": str,  # concatenated section text with summaries\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fused : list of tuples\n",
    "        [(doc_id, score, doc_dict), ...]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Organized results grouped by source_url.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by file path and line order (ascending)\n",
    "    # results['results'][0]['hits']\n",
    "    fused_sorted = sorted(\n",
    "        search_results[\"results\"][0][\"hits\"],\n",
    "        key=lambda x: (x.get(\"hybrid_search_info\").get(\"rank_fusion_score\")),\n",
    "        reverse=True,\n",
    "    )\n",
    "    fused_sorted = sorted(\n",
    "        fused_sorted,\n",
    "        key=lambda x: (\n",
    "            x.get(\"source_url\", \"\"),\n",
    "            x.get(\"line_start\", float(\"inf\")),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    final_docs: dict[str, dict] = {}\n",
    "\n",
    "    for doc in fused_sorted:\n",
    "        doc = doc[\"document\"]\n",
    "        source_url = doc.get(\"source_url\")\n",
    "        if not source_url:\n",
    "            # Skip if no source_url (invalid record)\n",
    "            continue\n",
    "\n",
    "        # Initialize file-level structure if not already present\n",
    "        file_entry = final_docs.setdefault(\n",
    "            source_url,\n",
    "            {\n",
    "                \"page_title\": doc.get(\"lvl0\", \"\"),\n",
    "                \"page_description\": doc.get(\"page_description\", \"\"),\n",
    "                \"content\": \"\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Build breadcrumb from lvl1–lvl6 hierarchy\n",
    "        breadcrumb = \" > \".join(\n",
    "            doc.get(f\"lvl{x}\") for x in range(1, 7) if doc.get(f\"lvl{x}\")\n",
    "        )\n",
    "\n",
    "        # Compose formatted section block\n",
    "        section_content = doc.get(\"section_content\", \"\").strip()\n",
    "        summary = doc.get(\"summary\", \"\").strip()\n",
    "\n",
    "        section_block = (\n",
    "            f\"\\n\"\n",
    "            f\"## {breadcrumb or '(No Section Title)'}\\n\"\n",
    "            f\"**Summary:** {summary or '(No summary)'}\\n\\n\"\n",
    "            f\"{section_content}\\n\"\n",
    "            f\"---\\n\"\n",
    "        )\n",
    "\n",
    "        # Append section block to this page’s content\n",
    "        file_entry[\"content\"] += section_block\n",
    "\n",
    "    return final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e28e05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = group_search_results(results)\n",
    "# results['results'][0]['hits'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b2f12b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://imagekit.io/docs/video-resize-and-crop': {'page_title': 'Resize and Crop Videos',\n",
       "  'page_description': 'Learn how to resize and crop videos using the ImageKit.io URL-based transformation parameters.',\n",
       "  'content': '\\n## Video smart crop pricing\\n**Summary:** This section explains that video smart crop has extra charges beyond standard video encoding, calculated from the final video duration, the number of smart crop (`fo`) operations, and the SD VPU rate. It provides a cost formula in code format: `Smart crop cost = Final video duration (in seconds) × Number of fo parameters used × VPU rate for SD video`.\\n\\nVideo smart crop incurs additional charges beyond the standard [video encoding costs](video-transformation#pricing). The smart crop fee is calculated based on two factors:\\n\\n1. **Duration of the final video output** (in seconds).\\n2. **Number of smart crop operations** used in the transformation.\\n\\nThe formula for calculating the smart crop cost is:\\n\\n```\\nSmart crop cost = Final video duration (in seconds) × Number of `fo` parameters used × VPU rate for SD video\\n```\\n---\\n\\n## Automatic smart crop - (fo-auto)\\n**Summary:** This section describes `fo-auto`, which automatically detects and tracks key objects in a video to keep them centered, requiring explicit dimensions via height/width or width plus `ar` to maintain aspect ratio. It provides tabbed URL and video examples for the original clip, a 3:4 smart crop, and an exact 480×360 extract using `cm-extract`.\\n\\nAutomatically detects and tracks the most important objects in your video, ensuring they remain centered as the video progresses. This feature is ideal for creating engaging social media content from longer videos. When using `fo-auto`, you must specify both dimensions—either provide both `height` and `width`, or specify one dimension along with the `ar` (aspect ratio) parameter. The unspecified dimension will be calculated automatically to maintain the aspect ratio.\\n\\n{% linetabs %}\\n{% linetab title=\"Original scene (960x506)\" %}\\n\\nURL - [https://ik.imagekit.io/demo/skateboarding.mp4](https://ik.imagekit.io/demo/skateboarding.mp4)\\n\\n{%video src=\"https://ik.imagekit.io/demo/skateboarding.mp4?tr=f-auto\" /%}\\n\\n{% /linetab %}\\n{% linetab title=\"Smart crop to 3:4 aspect ratio\" %}\\n\\nURL - [https://ik.imagekit.io/demo/skateboarding.mp4?tr=fo-auto,w-300,ar-3_4](https://ik.imagekit.io/demo/skateboarding.mp4?tr=fo-auto,w-300,ar-3_4)\\n\\nThe AI automatically keeps the skateboarder in focus while converting to a vertical format, perfect for social media.\\n\\n{%video src=\"https://ik.imagekit.io/demo/skateboarding.mp4?tr=fo-auto,w-300,ar-3_4\" /%}\\n\\n{% /linetab %}\\n{% linetab title=\"Extract exact dimensions\" %}\\n\\nURL - [https://ik.imagekit.io/demo/skateboarding.mp4?tr=fo-auto,w-480,h-360,cm-extract](https://ik.imagekit.io/demo/skateboarding.mp4?tr=fo-auto,w-480,h-360,cm-extract)\\n\\nExtract a precise 480×360 section while keeping the action centered throughout the video.\\n\\n{%video src=\"https://ik.imagekit.io/demo/skateboarding.mp4?tr=fo-auto,w-480,h-360,cm-extract\" /%}\\n\\n{% /linetab %}\\n{% /linetabs %}\\n---\\n\\n## Limitations and considerations for video smart crop\\n**Summary:** This section lists functional limitations and ordering rules for using video smart crop, including compatible crop modes, unsupported input formats (MPEG-1, MPEG-2, GIF layers, image overlays), the requirement that smart crop be the first chained transformation, incompatibility with rotate in the same step, and the ban on arithmetic expressions. It includes URL transformation examples showing valid and invalid parameter orders for smart crop and rotation.\\n\\n{% callout style=\"warning\" %}\\n**Crop mode compatibility:** Video smart crop only works with `c-maintain_ratio` (default) and `cm-extract` crop modes. All other crop modes (defined with `c` or `cm`) are invalid.\\n{% /callout %}\\n\\n1. Video smart crop is available when base asset is video and inside video overlays (`l-video`). However, video smart crop is not available when input video codec is `MPEG-1 Video` or `MPEG-2 Video`.\\n2. Video smart crop is not available when input of video layer (`l-video`) is a GIF file.\\n3. Video smart crop is not available for image overlays (`l-image`) in video transformations.\\n4. Smart crop can only be performed on a video once, and it must be the first step of the chained transformations. \\\\\\n`tr=b-10_red:fo-person` - ❌ \\\\\\n`tr=fo-person:b-10_red` - ✅ \\\\\\nIf you use smart crop inside a video layer (`l-video`), it must also be the first step within that layer’s chained transformations.\\n5. You cannot use rotate (`rt`) in the same step as smart crop. \\\\\\n`tr=fo-person,rt-90` - ❌ \\\\\\nIf you want to rotate a video after applying smart crop, use chained transformation (separate the parameters with a `:`). \\\\\\n`tr=fo-person:rt-90` - ✅ will first crop around the `person` in the video, and then rotate the result by 90 degrees.\\n6. Arithmetic expressions are completely unsupported anywhere in the transformation when video smart crop is used.\\n---\\n\\n## Object-aware cropping - (fo-object name)\\n**Summary:** This section explains object-aware cropping (`fo-<object>`), where you specify an object from a supported list so AI keeps that object in focus, with examples focusing on a dog or a person via URLs and embedded videos. An info callout notes that with `fo-face` or `fo-<object>`, width and height can be omitted while using `ar` so the AI auto-sizes the crop to the chosen aspect ratio.\\n\\nFocus on specific objects in your video by specifying any object from the [supported list](image-resize-and-crop#supported-object-list). The AI will track and keep the specified object in focus throughout the video.\\n\\n{% linetabs %}\\n{% linetab title=\"Original scene (720x1280)\" %}\\n\\nURL - [https://ik.imagekit.io/demo/bench.mp4](https://ik.imagekit.io/demo/bench.mp4)\\n\\n{%video src=\"https://ik.imagekit.io/demo/bench.mp4?tr=f-auto\" /%}\\n{% /linetab %}\\n{% linetab title=\"Focus on dog\" %}\\n\\nURL - [https://ik.imagekit.io/demo/bench.mp4?tr=fo-dog](https://ik.imagekit.io/demo/bench.mp4?tr=fo-dog)\\n\\nIntelligently crop the video to keep the dog in the view.\\n\\n{%video src=\"https://ik.imagekit.io/demo/bench.mp4?tr=fo-dog\" /%}\\n{% /linetab %}\\n{% linetab title=\"Focus on person\" %}\\n\\nURL - [https://ik.imagekit.io/demo/bench.mp4?tr=fo-person](https://ik.imagekit.io/demo/bench.mp4?tr=fo-person)\\n\\nIntelligently crop the video to keep the person in the view.\\n\\n{%video src=\"https://ik.imagekit.io/demo/bench.mp4?tr=fo-person\" /%}\\n{% /linetab %}\\n{% /linetabs %}\\n\\n{% callout style=\"info\" %}\\n**Auto-sizing with smart crop:** When using face crop (`fo-face`) or object-aware cropping (`fo-<object>`), you can omit width and height parameters to let the AI automatically determine the optimal crop size. Use the `ar` parameter to specify your preferred aspect ratio, and the AI will adjust the crop area to match while keeping the subject in focus.\\n{% /callout %}\\n---\\n\\n## Focus - (fo)\\n**Summary:** This section explains the `fo` (focus) parameter, detailing its allowed values for pad resize and extract crop and how it changes padding or cropping behavior. It also describes AI-powered smart cropping modes (`fo-auto`, `fo-face`, and `fo-<object>`) that automatically detect and track subjects in videos.\\n\\nThis parameter can be used along with [pad resize](#pad-resize-crop-strategy---cm-pad_resize), [maintain ratio](#maintain-ratio-crop-strategy---c-maintain_ratio) or [extract crop](#extract-crop-strategy---cm-extract) to change the behavior of padding or cropping. Learn more from the different examples shown in respective sections.\\n\\nThis parameter can have the following values depending upon where it is being used:\\n\\n1. `left`, `right`, `top`, `bottom` can be to control the position of padding when used with pad resize. [Learn from examples](#example---all-padding-on-one-side).\\n2. `center`, `top`, `left`, `bottom`, `right`, `top_left`, `top_right`, `bottom_left` and `bottom_right` can be used to define relative cropping during extract crop. [Learn from examples](#examples---center-and-relative-focus).\\n\\nBeyond static positioning, the `fo` parameter also supports AI-powered smart cropping that can automatically detect and track subjects throughout your video. This includes automatic smart crop (`fo-auto`) for general content, face detection and tracking (`fo-face`), and object-aware cropping (`fo-<object>`) that can focus on specific objects like people, cars, or animals from our supported object list.\\n---\\n\\n## Face crop - (fo-face)\\n**Summary:** This section covers `fo-face`, which detects and follows faces in a video, centering the most prominent face and optionally using aspect ratio or explicit width/height with `cm-extract`. It includes tabbed URL and video examples for the original scene, automatic face crop, 9:16 vertical face crop, and a fixed 400×600 face-focused extract.\\n\\nDetects and follows faces in your video, automatically keeping them centered and in focus. When multiple faces are present, it focuses on the most prominent one.\\n\\n{% linetabs %}\\n{% linetab title=\"Original scene (1942x1024)\" %}\\n\\nURL - [https://ik.imagekit.io/demo/speak-phone.mp4](https://ik.imagekit.io/demo/speak-phone.mp4)\\n\\n{%video src=\"https://ik.imagekit.io/demo/speak-phone.mp4?tr=f-auto\" /%}\\n\\n{% /linetab %}\\n{% linetab title=\"Auto-crop to face\" %}\\n\\nURL - [https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face](https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face)\\n\\nAutomatically determines the optimal crop size to keep the face in focus throughout the video.\\n\\n{%video src=\"https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face\" /%}\\n\\n{% /linetab %}\\n{% linetab title=\"Face crop with 9:16 aspect ratio\" %}\\n\\nURL - [https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face,ar-9_16](https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face,ar-9_16)\\n\\nPerfect for creating vertical videos for mobile platforms while keeping the face centered.\\n\\n{%video src=\"https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face,ar-9_16\" /%}\\n\\n{% /linetab %}\\n{% linetab title=\"Extract specific dimensions\" %}\\n\\nURL - [https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face,w-400,h-600,cm-extract](https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face,w-400,h-600,cm-extract)\\n\\nExtract a 400×600 portion while keeping the face optimally positioned.\\n\\n{%video src=\"https://ik.imagekit.io/demo/speak-phone.mp4?tr=fo-face,w-400,h-600,cm-extract\" /%}\\n\\n{% /linetab %}\\n{% /linetabs %}\\n---\\n\\n## Maintain ratio crop strategy - (c-maintain_ratio)\\n**Summary:** (No summary)\\n\\nThis is the default crop strategy. If no crop (`c`) or crop_mode (`cm`) is specified in the URL, `c-maintain_ratio` gets applied automatically.\\n\\nIn this strategy, the output video\\'s dimensions (height and width) are the same as requested, and the aspect ratio is preserved. This is accomplished by resizing the video to the requested dimension and then cropping extra parts to get the desired height & width.\\n\\n{% callout style=\"info\" %}\\nBy default, ImageKit.io crops the video from the center, but you can change this using the [focus parameter](#focus---fo).\\n{% /callout %}\\n\\n{% linetabs %}\\n{% linetab title=\"Original\" %}\\nURL - [https://ik.imagekit.io/demo/sample-video.mp4](https://ik.imagekit.io/demo/sample-video.mp4)\\n\\n{% video src=\"https://ik.imagekit.io/demo/sample-video.mp4\" alt=\"Original video\" /%}\\n\\n{% /linetab %}\\n\\n{% linetab title=\"w-400,h-300,c-maintain_ratio\" %}\\nURL - [https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300,c-maintain_ratio](https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300,c-maintain_ratio)\\n\\n[`w-400,h-300,c-maintain_ratio`](https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300,c-maintain_ratio) is equivalent to [`w-400,h-300`](https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300) because `maintain_ratio` is the default crop strategy.\\n\\nNotice that the video\\'s dimension matches 400x300, but the content is cropped from all edges, i.e., by default, ImageKit will extract the video from the center.\\n\\n{%video src=\"https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300,c-maintain_ratio\" alt=\"w-400,h-300,c-maintain_ratio\" /%}\\n{% /linetab %}\\n\\n{% linetab title=\"w-400,h-300,c-maintain_ratio,fo-left\" %}\\nURL - [https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300,c-maintain_ratio,fo-left](https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300,c-maintain_ratio,fo-left)\\n\\nUsing the [focus (`fo`) parameter](#focus---fo), you can specify the side to crop from.\\n\\nHere the video\\'s dimension matches 400x300 and crops out the content on right side, because focus (`fo`) is set to `left`.\\n\\n{%video src=\"https://ik.imagekit.io/demo/sample-video.mp4?tr=w-400,h-300,c-maintain_ratio,fo-left\" alt=\"w-400,h-300,c-maintain_ratio,fo-left\" /%}\\n\\n{% /linetab %}\\n{% /linetabs %}\\n---\\n'},\n",
       " 'https://imagekit.io/docs/video-transformation': {'page_title': 'Video Transformation',\n",
       "  'page_description': 'Learn how to transform videos using the ImageKit.io URL-based transformation parameters.',\n",
       "  'content': '\\n## Pricing\\n**Summary:** This section defines how Video Processing Units (VPUs) are calculated for video transformations based on output duration, resolution, and codec, including formulas, per-second unit rates, and a resolution classification table, plus special rules for audio extraction, adaptive bitrate streaming, thumbnails, and smart crop. It matters because it explains exactly which transformations incur processing costs and how to estimate or optimize billing impact.\\n\\nEvery new video transformation that has never been done before will contribute toward video processing units using the below definition. Subsequent views of the same video transformation only count towards bandwidth.\\n\\nVideo processing units used depend on output video codec, duration, and resolution.\\n\\nCalculation of units for resolution:\\n\\n* 1 second of SD video output = 1 unit\\n* 1 second of HD video output = 2 units\\n* 1 second of 4K video output = 4 units\\n* 1 second of 8K video output = 8 units\\n* 1 second of 16K video output = 16 units\\n\\nCalculation of units for video codec:\\n\\n* 1 second of video output in H.264 codec = 1 unit\\n* 1 second of video output in VP9 codec = 1 unit\\n* 1 second of video output in AV1 codec = 10 units\\n\\nVPU (Video Processing Unit) usage = Duration (in seconds) × Resolution (in units) × Video Codec (in units)\\n\\nSpecial operations:\\n\\n* **Audio extraction** - Using [`vc-none`](/audio-transformations#extracting-audio) transformation results in audio output. This operation is equal to processing the input video in SD output resolution for the duration of the output audio.\\n* **Adaptive bitrate streaming** - This operation is equal to processing a 30 seconds SD resolution video. In addition, all generated representations are charged based on requested resolutions.\\n* **Get thumbnail** - This operation is equal to processing a 30-second SD resolution video.\\n* **Video smart crop** - 1 VPU per second of output for each smart crop requested using `fo` parameter.\\n\\nWe define resolutions in terms of total pixel count as the following.\\n\\n| Resolution | Description                                                      |\\n| ---------- | ---------------------------------------------------------------- |\\n| SD         | Less than 921,600 total pixels, i.e., less than 1280 × 720.      |\\n| HD         | Greater than or equal to 1280 × 720 but less than 3840 × 2160.   |\\n| 4K         | Greater than or equal to 3840 × 2160 but less than 7680 × 4320.  |\\n| 8K         | Greater than or equal to 7680 × 4320 but less than 15360 × 8640. |\\n| 16K        | Greater than or equal to 15360 × 8640.                           |\\n---\\n'},\n",
       " 'https://imagekit.io/docs/image-resize-and-crop': {'page_title': 'Resize and crop images',\n",
       "  'page_description': \"Learn how to resize and crop images using ImageKit.io's real-time URL-based transformation API.\",\n",
       "  'content': '\\n## Auto smart cropping - (fo-auto)\\n**Summary:** This section covers auto smart cropping (`fo-auto`), where ImageKit.io automatically finds and preserves the most important part of an image in a thumbnail by adding `fo-auto` to the URL. It shows, via example URLs and images, how smart crop recenters the main subject compared to regular cropping when generating resized thumbnails.\\n\\nIn this mode, ImageKit.io automatically determines the most important part of the image and preserves it in the output thumbnail. This is enabled by passing the `fo-auto` parameter in the URL transformation parameters.\\n\\n{% linetabs %}\\n{% linetab title=\"Original image\" %}\\n[https://ik.imagekit.io/ikmedia/docs_images/examples/Smart_crop_example.jpg](https://ik.imagekit.io/ikmedia/docs_images/examples/Smart_crop_example.jpg)\\n\\nFor example, in the image below, the child is the main subject, and he is slightly towards the right from the center of the image.\\n\\n![Original Image](<https://ik.imagekit.io/ikmedia/docs_images/examples/Smart_crop_example.jpg>)\\n\\n{% /linetab %}\\n\\n{% linetab title=\"Regular cropping\" %}\\n[https://ik.imagekit.io/ikmedia/tr:w-200,h-300/docs_images/examples/Smart_crop_example.jpg](https://ik.imagekit.io/ikmedia/tr:w-200,h-300/docs_images/examples/Smart_crop_example.jpg)\\n\\nIf we use regular resize and the default crop strategy, we get the following result, where the main subject is off the center. This is definitely not a great thumb image to have.\\n\\n![Regular Cropping](<https://ik.imagekit.io/ikmedia/tr:w-200,h-300/docs_images/examples/Smart_crop_example.jpg>)\\n\\n{% /linetab %}\\n\\n{% linetab title=\"Smart crop (fo-auto)\" %}\\n[https://ik.imagekit.io/ikmedia/tr:w-200,h-300,fo-auto/docs_images/examples/Smart_crop_example.jpg](https://ik.imagekit.io/ikmedia/tr:w-200,h-300,fo-auto/docs_images/examples/Smart_crop_example.jpg)\\n\\nWith smart crop auto mode, this is what the final result looks like. The main subject is right in the center of the final thumbnail.\\n\\n![Smart crop (fo-auto)](<https://ik.imagekit.io/ikmedia/tr:w-200,h-300,fo-auto/docs_images/examples/Smart_crop_example.jpg>)\\n\\n{% /linetab %}\\n{% /linetabs %}\\n---\\n'},\n",
       " 'https://imagekit.io/docs/transformations': {'page_title': 'Transform and adapt media assets',\n",
       "  'page_description': 'Learn how URL-based transformations work in ImageKit and how to adapt media assets to your requirements.',\n",
       "  'content': '\\n## Transformations overview\\n**Summary:** This section provides a table summarizing available transformation categories for images and videos, including basic resize/crop, common effects, thumbnail generation, overlays, arithmetic and conditional transformations, AI-based image operations, and adaptive bitrate streaming for videos. It clarifies which features apply to images vs. videos and links to detailed docs for each transformation type.\\n\\nHere is a table of transformations that you can apply to your media assets:\\n\\n{% table %}\\n\\n- Transformation {% width=\"40%\" %}\\n- Images\\n- Videos\\n\\n---\\n\\n- Basic\\n- Resize, crop, smart crop images. [Learn more](/image-resize-and-crop).\\n- Resize and crop videos. [Learn more](/video-resize-and-crop).\\n\\n---\\n\\n- Common transformations\\n- All common image transformations like quality, format, rotation, border, etc. \\\\\\n[Learn more](/effects-and-enhancements).\\n- - All common video transformations like background color, border, radius, rotation, etc. [Learn more](/common-video-transformations).\\n- [Trim videos](/trim-videos) - control start and end time.\\n- [Audio related transformations](/audio-transformations) - mute vidoe, extract audio, etc.\\n\\n---\\n\\n- Generate thumbnails\\n- Generate thumbnails from vector and animated images. \\\\\\n[Learn more](/vector-and-animated-images).\\n- Create video thumbnails. \\\\\\n[Learn more](/create-video-thumbnails).\\n\\n---\\n\\n- Overlays\\n- Add image and text overlays on images. \\\\\\n[Learn more](/add-overlays-on-images).\\n- Add image, video, text, and subtitle overlays to videos. \\\\\\n[Learn more](/add-overlays-on-videos).\\n\\n---\\n- Arithmetic expressions\\n- Supported in images. \\\\\\n[Learn more](/arithmetic-expressions-in-transformations).\\n- Supported in videos. \\\\\\n[Learn more](/arithmetic-expressions-in-transformations).\\n\\n---\\n\\n- Conditional transformations\\n- You can apply transformations conditionally based on certain properties of the input asset. [Learn more](/conditional-transformations).\\n- Not supported in video.\\n\\n---\\n\\n- AI transformations\\n- Generate images via a text prompt, remove background, change background, crop objects, improve image quality, and more. [Learn more](/ai-transformations).\\n- Not supported in video.\\n\\n---\\n\\n- Adaptive bitrate streaming\\n- Not applicable.\\n- Use Adaptive Bitrate Streaming for long videos with ImageKit. \\\\\\n[Learn more](/adaptive-bitrate-streaming).\\n\\n{% /table %}\\n---\\n'}}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a8afd4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_PARAM_EXTRACTION_PROMPT = \"\"\"\n",
    "You are an ImageKit documentation interpreter.\n",
    "\n",
    "Your task:\n",
    "Given:\n",
    "1. A user query\n",
    "2. Documentation search results (raw content from ImageKit docs)\n",
    "\n",
    "Extract ONLY the transformation parameters that are:\n",
    "- Explicitly supported by the documentation\n",
    "- Directly relevant to the user query\n",
    "\n",
    "--------------------------------\n",
    "STRICT RULES (VERY IMPORTANT)\n",
    "--------------------------------\n",
    "- Extract ONLY parameters that appear explicitly in the documentation\n",
    "- Do NOT invent parameters\n",
    "- Do NOT invent default values\n",
    "- Do NOT output ImageKit short keys\n",
    "- Do NOT include pricing, cost formulas, or explanations\n",
    "- Do NOT include parameters that are restricted or incompatible\n",
    "- Respect documented limitations and ordering rules\n",
    "- If the query cannot be fulfilled reliably, return an empty list\n",
    "\n",
    "--------------------------------\n",
    "OUTPUT FORMAT (STRICT JSON ONLY)\n",
    "--------------------------------\n",
    "[\"param-value\", ....]\n",
    "\n",
    "--------------------------------\n",
    "USER QUERY\n",
    "--------------------------------\n",
    "{user_query}\n",
    "\n",
    "--------------------------------\n",
    "DOCUMENTATION CONTEXT\n",
    "--------------------------------\n",
    "{doc_context}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2b90298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_search_docs(search_docs_result: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Convert search_docs tool output into a readable text block\n",
    "    for LLM consumption.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "\n",
    "    for url, data in search_docs_result.items():\n",
    "        blocks.append(\n",
    "            f\"\"\"\n",
    "SOURCE: {url}\n",
    "TITLE: {data.get(\"page_title\")}\n",
    "DESCRIPTION: {data.get(\"page_description\")}\n",
    "\n",
    "CONTENT:\n",
    "{data.get(\"content\")}\n",
    "\"\"\".strip()\n",
    "        )\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b8d111c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_params_from_docs(\n",
    "    *,\n",
    "    user_query: str,\n",
    "    search_docs_result: Dict[str, Any],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract ImageKit transformation parameters from documentation context.\n",
    "\n",
    "    This function is intended to be used ONLY as a fallback when\n",
    "    CSV/schema-based transformation planning fails.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_query : str\n",
    "        Original user query (e.g. \"video-smart-crop for face-crop\")\n",
    "\n",
    "    search_docs_result : dict\n",
    "        Output from the search_docs tool:\n",
    "        {\n",
    "          \"url\": {\n",
    "              \"page_title\": \"...\",\n",
    "              \"page_description\": \"...\",\n",
    "              \"content\": \"...\"\n",
    "          }\n",
    "        }\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {\n",
    "          \"params\": { ... }\n",
    "        }\n",
    "        or {} if nothing can be extracted safely.\n",
    "    \"\"\"\n",
    "\n",
    "    doc_context = flatten_search_docs(search_docs_result)\n",
    "    # print(doc_context)\n",
    "    prompt = DOC_PARAM_EXTRACTION_PROMPT.format(\n",
    "        user_query=user_query,\n",
    "        doc_context=doc_context,\n",
    "    )\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You extract parameters strictly from documentation and output JSON only.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        # Absolute safety: never propagate malformed output\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c33374",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"video-smart-crop for face-crop for 300x300\"\n",
    "results = await search_docs(query=query)\n",
    "search_results = group_search_results(results)\n",
    "\n",
    "# params = await extract_params_from_docs(\n",
    "#     user_query=query,\n",
    "#     search_docs_result=search_results,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "940fd2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = await extract_params_from_docs(\n",
    "    user_query=query,\n",
    "    search_docs_result=search_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e2e0abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fo-face', 'w-300', 'h-300']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b39ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deprecation warning: AnalyticsRulesV1 is deprecated on v30+. Use client.analytics instead.\n",
      "/Users/shivamkaushik/Code/ik-agent/.venv/lib/python3.12/site-packages/pydantic/main.py:1809: UserWarning: Field name \"schema\" in \"Create_custom_metadata_fields_toolTool\" shadows an attribute in parent \"BaseModel\"\n",
      "  return meta(\n",
      "/Users/shivamkaushik/Code/ik-agent/.venv/lib/python3.12/site-packages/pydantic/main.py:1809: UserWarning: Field name \"schema\" in \"Update_custom_metadata_fields_toolTool\" shadows an attribute in parent \"BaseModel\"\n",
      "  return meta(\n"
     ]
    }
   ],
   "source": [
    "from src.tools.transformations.transformation import (\n",
    "    load_transform_metadata,\n",
    "    extract_unique_tags,\n",
    "    small_llm_filter,\n",
    "    filter_metadata,\n",
    "    big_llm_generate,\n",
    "    search_docs,\n",
    "    group_search_results,\n",
    "    extract_params_from_docs,\n",
    "    resolve_imagekit_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955faffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'methods': ['resize_and_crop'], 'tags': ['resize'], 'unresolved_intent': 'search for methods to add padding and image overlays'}\n"
     ]
    }
   ],
   "source": [
    "df = load_transform_metadata(\"static/ik_transforms.csv\")\n",
    "unique_tags = extract_unique_tags(df)\n",
    "\n",
    "user_query=\"resize image to 300x300 and add padding of 50 pixels, add image overlays\"\n",
    "\n",
    "output = await small_llm_filter(\n",
    "    user_query=user_query,\n",
    "    valid_methods=[\"resize_and_crop\"],\n",
    "    valid_tags=unique_tags,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f70a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_metadata = filter_metadata(\n",
    "    df=df,\n",
    "    tags=output[\"tags\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527746bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_plan = await big_llm_generate(\n",
    "    user_query=user_query,\n",
    "    filtered_metadata=filtered_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95bcde6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not structured_plan) or output.get(\"unresolved_intent\"):\n",
    "    raw_results = await search_docs(query=output.get(\"unresolved_intent\"))\n",
    "    grouped = group_search_results(raw_results)\n",
    "    doc_params = await extract_params_from_docs(\n",
    "        user_query=user_query,\n",
    "        search_docs_result=grouped,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12a376a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'w': '300', 'h': '300', 'cm': 'pad_resize'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d7e3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'method': 'resize_and_crop',\n",
       "  'params': {'width': 300, 'height': 300, 'crop_mode': 'pad_resize'}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae36f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import get_transform_key\n",
    "\n",
    "final_params_for_transformation = []\n",
    "if structured_plan:\n",
    "    normal_transformations = {}\n",
    "    overlay_transformations = []\n",
    "    for transformation in structured_plan:\n",
    "        if \"overlay\" not in transformation.get(\"method\"):\n",
    "            normal_transformations.update(transformation.get(\"params\"))\n",
    "        else:\n",
    "            overlay_transformations.append(transformation.get(\"params\"))\n",
    "    \n",
    "    final_params_for_transformation.append(normal_transformations)\n",
    "    final_params_for_transformation.extend(overlay_transformations)\n",
    "\n",
    "    if doc_params:\n",
    "        for p, v in doc_params.get('params').items():\n",
    "            k = get_transform_key(p)\n",
    "            final_params_for_transformation[0][k] = v\n",
    "\n",
    "else:\n",
    "    if doc_params:\n",
    "        out = {}\n",
    "        for p, v in doc_params.get('params').items():\n",
    "            k = get_transform_key(p)\n",
    "            out[k] = v\n",
    "        final_params_for_transformation.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c167e55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'width': '300', 'height': '300', 'crop_mode': 'pad_resize'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params_for_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8338448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"resize image to 300x300 and add focus on face\"\n",
    "transformation = await resolve_imagekit_transform(\n",
    "    user_query=user_query,\n",
    "    csv_path=\"static/ik_transforms.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09644f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'width': '300', 'height': '300', 'focus': 'face'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Validate and normalize ImageKit resize & crop parameters.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        width : int | float | str, optional\n",
      "            Output width. Accepts:\n",
      "            - int/float > 0\n",
      "            - string tokens like \"auto\"\n",
      "            - arithmetic expressions as strings (passed through)\n",
      "\n",
      "        height : int | float | str, optional\n",
      "            Output height. Same acceptance as width.\n",
      "\n",
      "        aspect_ratio : str, optional\n",
      "            Aspect ratio as \"<w>-<h>\" (e.g. \"16-9\") or an arithmetic expression string.\n",
      "\n",
      "        crop : {\"force\",\"at_max_enlarge\",\"at_least\",\"maintain_ratio\"}, optional\n",
      "            Default: \"maintain_ratio\"\n",
      "            Resize/crop strategy. Important:\n",
      "            - When crop='force', focus and zoom are not allowed.\n",
      "\n",
      "        crop_mode : {\"pad_resize\",\"pad_extract\",\"extract\"}, optional\n",
      "            Crop mode controlling padding/extraction.\n",
      "            - Coordinates (x,y,x_center,y_center) are ONLY allowed with crop_mode in {\"extract\",\"pad_extract\"}.\n",
      "\n",
      "        focus : str, optional\n",
      "            Focus parameter `fo` with context-sensitive values:\n",
      "\n",
      "            Allowed depending on usage:\n",
      "            - With crop_mode='pad_resize':\n",
      "                left, right, top, bottom  (padding position control)\n",
      "                auto, face, or any COCO class\n",
      "            - With crop_mode in {'extract','pad_extract'}:\n",
      "                center/top/left/bottom/right/top_left/top_right/bottom_left/bottom_right\n",
      "                custom\n",
      "                auto, face, or any COCO class\n",
      "            - With crop='maintain_ratio':\n",
      "                custom\n",
      "                auto, face, or any COCO class\n",
      "\n",
      "            Forbidden:\n",
      "            - If crop='force', focus is not allowed.\n",
      "\n",
      "        zoom : int | float | str, optional\n",
      "            Zoom factor `z`. Must be > 0 when numeric.\n",
      "            Forbidden when crop='force'.\n",
      "\n",
      "        x, y : int | float | str, optional\n",
      "            Absolute offsets (top-left origin) used for extraction crops.\n",
      "            Allowed only when crop_mode in {\"extract\",\"pad_extract\"}.\n",
      "            Cannot be mixed with x_center/y_center.\n",
      "\n",
      "        x_center, y_center : int | float | str, optional\n",
      "            Center offsets used for extraction crops.\n",
      "            Allowed only when crop_mode in {\"extract\",\"pad_extract\"}.\n",
      "            Cannot be mixed with x/y.\n",
      "\n",
      "        dpr : int | float | str, optional\n",
      "            Device pixel ratio. Must be > 0 when numeric.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Dict[str, str]\n",
      "            A dict with ImageKit short transformation keys.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        ValueError\n",
      "            If parameters are invalid or in conflict.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from src.modules.ik_transforms.transforms.resize_n_crop import ResizeAndCropTransforms\n",
    "\n",
    "print(ResizeAndCropTransforms.resize_and_crop.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64f2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ik-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
